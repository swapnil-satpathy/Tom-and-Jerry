# -*- coding: utf-8 -*-
"""Q2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1frdDzokg7DjK-o_lkIXxlDUNBdCoj1JT
"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import cv2
import keras
import sklearn

df=pd.read_csv("/db5fcca9-f52b-42a9-87be-26f77b6f9d97_train.csv")



from google.colab import drive
drive.mount('/content/drive')

image_directory = "/content/drive/My Drive/ntrain/"
files=[]
for f in df['image_file']:
    files.append(image_directory+"/"+str(f)+".jpg")

len(files)

training_labels=df['emotion']

data=[]
for f1 in files:
    img = cv2.imread(f1,0)
    data.append(img)

training_data=np.array(data)
training_data.shape



training_labels.shape

df2=pd.read_csv("/1062e440-bad5-415c-a209-d3a2a8336c2e_test.csv")

image_directory = "/content/drive/My Drive/ntest/"

files1=[]
for f in df2['image_file']:
    files1.append(image_directory+"/"+str(f)+".jpg")

data2=[]
for image in files1:
    img = cv2.imread(image,0)
    data2.append(img)

validation_data=np.array(data2)
validation_data.shape

import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten
from tensorflow.keras.layers import Conv2D, MaxPooling2D

training_data=training_data/255.0
validation_data=validation_data/255.0

tensorflow_training_data=training_data.reshape(training_data.shape[0],training_data.shape[1],training_data.shape[2],1)
tensorflow_validation_data=validation_data.reshape(validation_data.shape[0],validation_data.shape[1],validation_data.shape[2],1)

from keras.layers.normalization import BatchNormalization
model=Sequential()
model.add(Conv2D(32, (3,3), input_shape=(tensorflow_training_data.shape[1],tensorflow_training_data.shape[2],tensorflow_training_data.shape[3])))
model.add(Activation('relu'))
BatchNormalization(axis=-1)
model.add(Conv2D(32, (3,3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2)))

BatchNormalization(axis=-1)
model.add(Conv2D(64, (3,3)))
model.add(Activation('relu'))
BatchNormalization(axis=-1)
model.add(Conv2D(64, (3,3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2,2)))

model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors


BatchNormalization()
model.add(Dense(512))
model.add(Activation('relu'))
BatchNormalization()
model.add(Dropout(0.2))
model.add(Dense(5))
model.add(Activation('softmax'))
model.summary()

model.compile(loss='sparse_categorical_crossentropy', metrics=['accuracy'], optimizer='adam')



model.fit(tensorflow_training_data,training_labels,batch_size=128,epochs=30)



predictions=np.argmax(model.predict(tensorflow_validation_data), axis=-1)

predictions.shape

dicti={}
dicti['emotion']=predictions

from google.colab import files
pd.DataFrame(dicti).to_csv('submission.csv',index=False) 
files.download('submission.csv')



